# ğŸ§  LLM Banking Assistant â€“ Frontend (Streamlit)

This is the **frontend interface** of a smart customer-service assistant for a banking system. The assistant leverages a **LoRA-fine-tuned Llama 3.2-3B-Instruct model** for answering FAQs and processing document uploads using Retrieval-Augmented Generation (RAG).

The frontend is built with **Streamlit**, providing a lightweight interface for end users to:

- ğŸ’¬ Chat with the assistant  
- ğŸ“„ Upload policy documents for updates  
- ğŸ§¹ Clear conversations  

> âš ï¸ Currently, this app uses **dummy API endpoints** for both chat and document upload. You can plug in your real endpoints later.

---

## ğŸš€ Features

- **Chat Interface**: Input queries and get simulated LLM-based responses
- **Document Upload**: Upload updated policies (PDFs) to simulate RAG integration
- **Clear Conversation**: Resets the chat session
- **Error Handling**: Graceful handling of API errors and validation issues

---

## ğŸ§© Tech Stack

- **Frontend Framework**: Streamlit
- **API Calls**: `requests`
- **Env Config**: `python-dotenv`

---

## ğŸ› ï¸ Setup Instructions

1. **Clone the repo**
   ```bash
   git clone https://github.com/Muhammad-AB/bankbot-llm
   cd bankbot-llm/Front-end
2. **Create a Virtual Environment (optional but recommended)**
   ```bash
   python -m venv venv
   source venv/bin/activate       # On Windows: venv\Scripts\activate
3. **Install the dependencies**
   ```bash
   pip install -r requirements.txt

4. **Run the Streamlit app**
   ```bash
   streamlit run app.py

---

## ğŸ“ Folder Structure
llm-banking-frontend/

â”‚

â”œâ”€â”€ app.py              # Main Streamlit entry point

â”œâ”€â”€ components.py       # UI components: chat UI, upload UI, layout

â”œâ”€â”€ utils.py            # Helper functions: API calls, state management

â”œâ”€â”€ requirements.txt    # Python dependencies

â””â”€â”€ README.md           # Youâ€™re here!
