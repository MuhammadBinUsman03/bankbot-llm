# ğŸ¦ BankBot-LLM

**BankBot-LLM** is an end-to-end pipeline for building a banking-focused language model. The project encompasses dataset preparation, fine-tuning, and inference stages, aiming to streamline domain-specific conversational AI in the finance sector.

---

## ğŸ“ Project Structure

```

bankbot-llm/
â”œâ”€â”€ ai_core/                        # Core backend logic (separate from bankbot-llm)
â”‚   â”œâ”€â”€ api/                        # FastAPI app setup
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â””â”€â”€ routes.py
â”‚   â”œâ”€â”€ database/                   # Vector database interface
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ qdrant_client.py
â”‚   â”œâ”€â”€ llm/                        # LLM interaction layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ client.py
â”‚   â”œâ”€â”€ models/                     # Embedding models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ embedding.py
â”‚   â”œâ”€â”€ processors/                 # Data preprocessing utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_processor.py
â”‚   â””â”€â”€ rag/                        # Retrieval-Augmented Generation chain logic
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py                 # Builds and executes the RAG chain
â”‚       â”œâ”€â”€ run_server.py           # Starts the FastAPI server
â”‚       â”œâ”€â”€ setup.py                # Configuration/setup script
â”‚       â””â”€â”€ .env.example            # Sample environment file
â”œâ”€â”€ bankbot-llm/                    # Project root folder
â”‚   â”œâ”€â”€ Dataset/
â”‚   â”‚   â””â”€â”€ Instruction Tuning Data/
â”‚   â”‚       â”œâ”€â”€ BankProducts_FineTuning.json
â”‚   â”‚       â”œâ”€â”€ Finetuning_dataset_preparation.ipynb
â”‚   â”‚       â””â”€â”€ finetune_data.json
â”‚   â”œâ”€â”€ Fine-Tune/
â”‚   â”‚   â””â”€â”€ Fine-Tuning.ipynb
â”‚   â”œâ”€â”€ Inference/
â”‚   â”‚   â””â”€â”€ Inference.ipynb
â”‚   â”œâ”€â”€ frontend/                   # Frontend interface
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â”œâ”€â”€ components.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ services.py
â”‚   â”œâ”€â”€ Images/                     # Architecture diagram(s)
â”‚   â”‚   â””â”€â”€ llm_arch_2.png
â”‚   â””â”€â”€ README.md                   # Project overview documentation

````

## ğŸ“Š 1. Dataset Preparation

- **Notebook:** `Dataset/prepare_dataset.ipynb`
- **Output:** Cleaned and structured dataset ready for training

---

## ğŸ§  2. Fine-Tuning

- **Notebook:** `Fine-Tune/Fine-Tuning.ipynb`
- **Model:** A pre-trained LLM (e.g., LLaMA, Falcon, or similar)
- **Process:**
  - Load the preprocessed dataset
  - Tokenize and batch the input
  - Fine-tune the model on domain-specific Q&A data

Compatible with Google Colab or any GPU-enabled environment.

---

## ğŸ” 3. Inference

- **Notebook:** `Inference/Inference.ipynb`
- **Description:**
  - Loads the fine-tuned model from Google Drive
  - Performs inference on user-defined queries
  - Returns model-generated answers

Supports both single-query testing and in batch
Compatible with Google Colab or any GPU-enabled environment.
---

## ğŸ“Œ Architecture Overview
This Diagram contains the complete architecture of the project (including the future work)
<p align="center">
  <img src="bankbot-llm\Images\llm _arch_2.png" alt="Architecture Diagram" width="700"/>
</p>

---

## ğŸš€ Getting Started

### Clone the repository
```bash
git clone https://github.com/MuhammadBinUsman03/bankbot-llm.git
cd bankbot-llm
````

## âœ… Requirements

* Python â‰¥ 3.12
* Jupyter or Google Colab (with GPU for fine-tuning or inference)
* `transformers`
* `datasets`
* `pandas`, `numpy`, `openpyxl`
* `torch` or `tensorflow` (based on model backend)

## SETUP
Pull the Local running Qdrant image
```bash
docker pull qdrant/qdrant
```
Start Qdrant container at Port `6333` and `6334`
```bash
docker run -p 6333:6333 -p 6334:6334 \
    -v "$(pwd)/qdrant_storage:/qdrant/storage:z" \
    qdrant/qdrant
```
Start the FastAPI server at port `8080` for AI inference
```bash
cd ai_core
pip install -e .
python run_server.py --host 0.0.0.0 --port 8080 --qdrant-url http://localhost:6333 --reload
```
Start the Streamlit Frontend at port `8502`

```bash
cd ../bankbot-llm/Front-end
pip install -r requirements.txt
streamlit run app.py
```

